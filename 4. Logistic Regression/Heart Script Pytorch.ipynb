{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25899c84",
   "metadata": {},
   "source": [
    "## PyTorch installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082dcc7",
   "metadata": {},
   "source": [
    "pip install torch torchvision torchaudio\n",
    "\n",
    "for more information https://pytorch.org/get-started/locally/\n",
    "\n",
    "pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084eedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be37dda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca9d1d",
   "metadata": {},
   "source": [
    "### (0) Preparing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111d317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data set\n",
    "T = np.loadtxt('heart.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9630acd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    }
   ],
   "source": [
    "print(len(T[:, 13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f108a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the real features\n",
    "X_numpy = T[:, [0, 3, 4, 7, 9, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be1a0321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Extract and transform the markers\n",
    "Y_numpy = T[:, 13] - 1\n",
    "print(Y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9fa44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.00e+01 1.30e+02 3.22e+02 1.09e+02 2.40e+00 3.00e+00]\n",
      " [6.70e+01 1.15e+02 5.64e+02 1.60e+02 1.60e+00 0.00e+00]\n",
      " [5.70e+01 1.24e+02 2.61e+02 1.41e+02 3.00e-01 0.00e+00]\n",
      " ...\n",
      " [5.60e+01 1.40e+02 2.94e+02 1.53e+02 1.30e+00 0.00e+00]\n",
      " [5.70e+01 1.40e+02 1.92e+02 1.48e+02 4.00e-01 0.00e+00]\n",
      " [6.70e+01 1.60e+02 2.86e+02 1.08e+02 1.50e+00 3.00e+00]]\n",
      "tensor([[7.0000e+01, 1.3000e+02, 3.2200e+02, 1.0900e+02, 2.4000e+00, 3.0000e+00],\n",
      "        [6.7000e+01, 1.1500e+02, 5.6400e+02, 1.6000e+02, 1.6000e+00, 0.0000e+00],\n",
      "        [5.7000e+01, 1.2400e+02, 2.6100e+02, 1.4100e+02, 3.0000e-01, 0.0000e+00],\n",
      "        ...,\n",
      "        [5.6000e+01, 1.4000e+02, 2.9400e+02, 1.5300e+02, 1.3000e+00, 0.0000e+00],\n",
      "        [5.7000e+01, 1.4000e+02, 1.9200e+02, 1.4800e+02, 4.0000e-01, 0.0000e+00],\n",
      "        [6.7000e+01, 1.6000e+02, 2.8600e+02, 1.0800e+02, 1.5000e+00, 3.0000e+00]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# from numpy array to tensor\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "print(X_numpy)\n",
    "print(X)\n",
    "print(X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32873bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 1.]\n",
      "tensor([1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# from numpy array to tensor\n",
    "Y = torch.from_numpy(Y_numpy.astype(np.float32))\n",
    "# Y = Y.view(Y.shape[0], 1)\n",
    "print(Y_numpy)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d15e669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 6\n"
     ]
    }
   ],
   "source": [
    "# Number of data pairs and features \n",
    "m, d = X.shape\n",
    "print(m, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8bfdb",
   "metadata": {},
   "source": [
    "### (1) Splitting our dataset into a train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc5bff",
   "metadata": {},
   "source": [
    "Random selection of the indices of the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428786b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.0\n"
     ]
    }
   ],
   "source": [
    "# Share of training data\n",
    "p = 0.7\n",
    "data_ind = np.random.permutation(m)\n",
    "print((np.ceil(p*m)+1))\n",
    "ind_train = data_ind[:int((np.ceil(p*m)+1))]\n",
    "ind_test = [i for i in data_ind if i not in ind_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea7a13c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 51., 140., 261., 186.,   0.,   0.],\n",
      "        [ 49., 130., 269., 163.,   0.,   0.],\n",
      "        [ 41., 126., 306., 163.,   0.,   0.],\n",
      "        ...,\n",
      "        [ 47., 108., 243., 152.,   0.,   0.],\n",
      "        [ 58., 100., 248., 122.,   1.,   0.],\n",
      "        [ 61., 130., 330., 169.,   0.,   0.]])\n",
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "X_train = X[ind_train, :]\n",
    "Y_train = Y[ind_train]\n",
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e081d4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.4000e+01, 1.2000e+02, 2.4600e+02, 9.6000e+01, 2.2000e+00, 1.0000e+00],\n",
      "        [6.4000e+01, 1.2800e+02, 2.6300e+02, 1.0500e+02, 2.0000e-01, 1.0000e+00],\n",
      "        [5.1000e+01, 1.0000e+02, 2.2200e+02, 1.4300e+02, 1.2000e+00, 0.0000e+00],\n",
      "        [6.2000e+01, 1.2400e+02, 2.0900e+02, 1.6300e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [5.0000e+01, 1.4400e+02, 2.0000e+02, 1.2600e+02, 9.0000e-01, 0.0000e+00],\n",
      "        [4.6000e+01, 1.3800e+02, 2.4300e+02, 1.5200e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [5.4000e+01, 1.6000e+02, 2.0100e+02, 1.6300e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [5.8000e+01, 1.0000e+02, 2.3400e+02, 1.5600e+02, 1.0000e-01, 1.0000e+00],\n",
      "        [4.6000e+01, 1.0100e+02, 1.9700e+02, 1.5600e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [4.6000e+01, 1.4000e+02, 3.1100e+02, 1.2000e+02, 1.8000e+00, 2.0000e+00],\n",
      "        [6.4000e+01, 1.3000e+02, 3.0300e+02, 1.2200e+02, 2.0000e+00, 2.0000e+00],\n",
      "        [5.9000e+01, 1.7000e+02, 3.2600e+02, 1.4000e+02, 3.4000e+00, 0.0000e+00],\n",
      "        [4.2000e+01, 1.3600e+02, 3.1500e+02, 1.2500e+02, 1.8000e+00, 0.0000e+00],\n",
      "        [5.2000e+01, 1.3600e+02, 1.9600e+02, 1.6900e+02, 1.0000e-01, 0.0000e+00],\n",
      "        [6.3000e+01, 1.0800e+02, 2.6900e+02, 1.6900e+02, 1.8000e+00, 2.0000e+00],\n",
      "        [6.6000e+01, 1.5000e+02, 2.2600e+02, 1.1400e+02, 2.6000e+00, 0.0000e+00],\n",
      "        [4.9000e+01, 1.2000e+02, 1.8800e+02, 1.3900e+02, 2.0000e+00, 3.0000e+00],\n",
      "        [5.0000e+01, 1.1000e+02, 2.5400e+02, 1.5900e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [4.5000e+01, 1.2800e+02, 3.0800e+02, 1.7000e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [6.2000e+01, 1.4000e+02, 3.9400e+02, 1.5700e+02, 1.2000e+00, 0.0000e+00],\n",
      "        [6.0000e+01, 1.0200e+02, 3.1800e+02, 1.6000e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [4.4000e+01, 1.1000e+02, 1.9700e+02, 1.7700e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [3.4000e+01, 1.1800e+02, 1.8200e+02, 1.7400e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [5.5000e+01, 1.8000e+02, 3.2700e+02, 1.1700e+02, 3.4000e+00, 0.0000e+00],\n",
      "        [4.4000e+01, 1.4000e+02, 2.3500e+02, 1.8000e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [5.8000e+01, 1.5000e+02, 2.8300e+02, 1.6200e+02, 1.0000e+00, 0.0000e+00],\n",
      "        [5.2000e+01, 1.5200e+02, 2.9800e+02, 1.7800e+02, 1.2000e+00, 0.0000e+00],\n",
      "        [5.9000e+01, 1.3500e+02, 2.3400e+02, 1.6100e+02, 5.0000e-01, 0.0000e+00],\n",
      "        [6.1000e+01, 1.3800e+02, 1.6600e+02, 1.2500e+02, 3.6000e+00, 1.0000e+00],\n",
      "        [5.4000e+01, 1.2000e+02, 1.8800e+02, 1.1300e+02, 1.4000e+00, 1.0000e+00],\n",
      "        [4.4000e+01, 1.1200e+02, 2.9000e+02, 1.5300e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [6.2000e+01, 1.2800e+02, 2.0800e+02, 1.4000e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [4.6000e+01, 1.5000e+02, 2.3100e+02, 1.4700e+02, 3.6000e+00, 0.0000e+00],\n",
      "        [4.3000e+01, 1.3000e+02, 3.1500e+02, 1.6200e+02, 1.9000e+00, 1.0000e+00],\n",
      "        [5.7000e+01, 1.2800e+02, 3.0300e+02, 1.5900e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [4.8000e+01, 1.2400e+02, 2.5500e+02, 1.7500e+02, 0.0000e+00, 2.0000e+00],\n",
      "        [5.1000e+01, 1.4000e+02, 2.9900e+02, 1.7300e+02, 1.6000e+00, 0.0000e+00],\n",
      "        [5.2000e+01, 1.2800e+02, 2.5500e+02, 1.6100e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [5.9000e+01, 1.7000e+02, 2.8800e+02, 1.5900e+02, 2.0000e-01, 0.0000e+00],\n",
      "        [6.0000e+01, 1.3000e+02, 2.0600e+02, 1.3200e+02, 2.4000e+00, 2.0000e+00],\n",
      "        [4.2000e+01, 1.2000e+02, 2.9500e+02, 1.6200e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3000e+01, 1.1500e+02, 3.0300e+02, 1.8100e+02, 1.2000e+00, 0.0000e+00],\n",
      "        [4.1000e+01, 1.3000e+02, 2.0400e+02, 1.7200e+02, 1.4000e+00, 0.0000e+00],\n",
      "        [5.2000e+01, 1.7200e+02, 1.9900e+02, 1.6200e+02, 5.0000e-01, 0.0000e+00],\n",
      "        [6.6000e+01, 1.6000e+02, 2.4600e+02, 1.2000e+02, 0.0000e+00, 3.0000e+00],\n",
      "        [6.2000e+01, 1.3000e+02, 2.3100e+02, 1.4600e+02, 1.8000e+00, 3.0000e+00],\n",
      "        [5.0000e+01, 1.2900e+02, 1.9600e+02, 1.6300e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [4.7000e+01, 1.1200e+02, 2.0400e+02, 1.4300e+02, 1.0000e-01, 0.0000e+00],\n",
      "        [5.5000e+01, 1.3200e+02, 3.5300e+02, 1.3200e+02, 1.2000e+00, 1.0000e+00],\n",
      "        [4.2000e+01, 1.2000e+02, 2.0900e+02, 1.7300e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [6.1000e+01, 1.3400e+02, 2.3400e+02, 1.4500e+02, 2.6000e+00, 2.0000e+00],\n",
      "        [6.5000e+01, 1.5000e+02, 2.2500e+02, 1.1400e+02, 1.0000e+00, 3.0000e+00],\n",
      "        [4.6000e+01, 1.4200e+02, 1.7700e+02, 1.6000e+02, 1.4000e+00, 0.0000e+00],\n",
      "        [5.7000e+01, 1.5200e+02, 2.7400e+02, 8.8000e+01, 1.2000e+00, 1.0000e+00],\n",
      "        [5.2000e+01, 1.2800e+02, 2.0500e+02, 1.8400e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [5.4000e+01, 1.2500e+02, 2.7300e+02, 1.5200e+02, 5.0000e-01, 1.0000e+00],\n",
      "        [6.0000e+01, 1.2500e+02, 2.5800e+02, 1.4100e+02, 2.8000e+00, 1.0000e+00],\n",
      "        [4.4000e+01, 1.1800e+02, 2.4200e+02, 1.4900e+02, 3.0000e-01, 1.0000e+00],\n",
      "        [6.0000e+01, 1.1700e+02, 2.3000e+02, 1.6000e+02, 1.4000e+00, 2.0000e+00],\n",
      "        [5.3000e+01, 1.3000e+02, 2.6400e+02, 1.4300e+02, 4.0000e-01, 0.0000e+00],\n",
      "        [6.2000e+01, 1.3800e+02, 2.9400e+02, 1.0600e+02, 1.9000e+00, 3.0000e+00],\n",
      "        [6.7000e+01, 1.0000e+02, 2.9900e+02, 1.2500e+02, 9.0000e-01, 2.0000e+00],\n",
      "        [5.5000e+01, 1.4000e+02, 2.1700e+02, 1.1100e+02, 5.6000e+00, 0.0000e+00],\n",
      "        [5.7000e+01, 1.6500e+02, 2.8900e+02, 1.2400e+02, 1.0000e+00, 3.0000e+00],\n",
      "        [4.8000e+01, 1.3000e+02, 2.4500e+02, 1.8000e+02, 2.0000e-01, 0.0000e+00],\n",
      "        [5.9000e+01, 1.4000e+02, 1.7700e+02, 1.6200e+02, 0.0000e+00, 1.0000e+00],\n",
      "        [4.8000e+01, 1.3000e+02, 2.5600e+02, 1.5000e+02, 0.0000e+00, 2.0000e+00],\n",
      "        [4.7000e+01, 1.3800e+02, 2.5700e+02, 1.5600e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [6.7000e+01, 1.1500e+02, 5.6400e+02, 1.6000e+02, 1.6000e+00, 0.0000e+00],\n",
      "        [5.7000e+01, 1.5000e+02, 1.6800e+02, 1.7400e+02, 1.6000e+00, 0.0000e+00],\n",
      "        [5.3000e+01, 1.2300e+02, 2.8200e+02, 9.5000e+01, 2.0000e+00, 2.0000e+00],\n",
      "        [5.2000e+01, 1.2500e+02, 2.1200e+02, 1.6800e+02, 1.0000e+00, 2.0000e+00],\n",
      "        [3.8000e+01, 1.2000e+02, 2.3100e+02, 1.8200e+02, 3.8000e+00, 0.0000e+00],\n",
      "        [5.6000e+01, 1.3400e+02, 4.0900e+02, 1.5000e+02, 1.9000e+00, 2.0000e+00],\n",
      "        [4.8000e+01, 1.2200e+02, 2.2200e+02, 1.8600e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [6.9000e+01, 1.4000e+02, 2.3900e+02, 1.5100e+02, 1.8000e+00, 2.0000e+00],\n",
      "        [7.6000e+01, 1.4000e+02, 1.9700e+02, 1.1600e+02, 1.1000e+00, 0.0000e+00],\n",
      "        [4.1000e+01, 1.1000e+02, 1.7200e+02, 1.5800e+02, 0.0000e+00, 0.0000e+00],\n",
      "        [5.4000e+01, 1.2200e+02, 2.8600e+02, 1.1600e+02, 3.2000e+00, 2.0000e+00],\n",
      "        [5.3000e+01, 1.3000e+02, 1.9700e+02, 1.5200e+02, 1.2000e+00, 0.0000e+00]])\n",
      "tensor([1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "X_test = X[ind_test, :]\n",
    "Y_test = Y[ind_test]\n",
    "print(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9975668a",
   "metadata": {},
   "source": [
    "### (2) Building the PyTorch Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e318d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "     def __init__(self, input_dim, output_dim):\n",
    "         super(LogisticRegression, self).__init__()\n",
    "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "     def forward(self, x):\n",
    "         outputs = torch.sigmoid(self.linear(x))\n",
    "         return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004994e",
   "metadata": {},
   "source": [
    "### (3) Initializing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f6159e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning some hyper-parameters:\n",
    "epochs = 1000 # Indicates the number of passes through the entire training dataset the network has completed\n",
    "input_dim = d \n",
    "output_dim = 1 # Single output \n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07940631",
   "metadata": {},
   "source": [
    "<br>Epoch: Indicates the number of passes through the entire training dataset the network has completed\n",
    "<br>\n",
    "<br>Learning_rate: A tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function\n",
    "- High learning rate means you might never be able to reach a minimum.\n",
    "- Low learning rate will take longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f012bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78882187",
   "metadata": {},
   "source": [
    "### (4) Initializing the Loss Function and the Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9390e",
   "metadata": {},
   "source": [
    "##### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844ceaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "criterion_SGD = torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2917b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD: Implements stochastic gradient descent (optionally with momentum)\n",
    "optimizer_SGD = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28bc9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting learning rate\n",
    "# ExponentialLR: decays the learning rate of each parameter group by gamma every epoch.\n",
    "scheduler_SGD = torch.optim.lr_scheduler.ExponentialLR(optimizer_SGD, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c951a",
   "metadata": {},
   "source": [
    "##### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d0196c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "criterion_Adam = torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df30db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam: Implements Adam algorithm\n",
    "optimizer_Adam = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a85ab33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_Adam = torch.optim.lr_scheduler.ExponentialLR(optimizer_Adam, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8ed3b0",
   "metadata": {},
   "source": [
    "##### LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18da5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "criterion_LBFGS = torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91af36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBFGS: Implements L-BFGS algorithm, heavily inspired by minFunc\n",
    "optimizer_LBFGS = torch.optim.LBFGS(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "764eb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_LBFGS = torch.optim.lr_scheduler.ExponentialLR(optimizer_LBFGS, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e955d",
   "metadata": {},
   "source": [
    "### (5) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e6b8c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([190, 6])\n",
      "torch.Size([190])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "944c25b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                # Calculating the loss and accuracy for the train dataset\\n                total = 0\\n                correct = 0\\n                total += Y_train.size(0)\\n                correct += np.sum(torch.squeeze(outputs).round().detach().numpy() == Y_train.detach().numpy())\\n                accuracy = 100 * correct/total\\n                losses.append(loss.item())\\n                Iterations.append(iter)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def training_model(criterion, optimizer, scheduler):\n",
    "    losses = []\n",
    "    losses_test = []\n",
    "    Iterations = []\n",
    "    iter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    # for epoch in tqdm(range(int(epochs)),desc='Training Epochs'):\n",
    "        x = X_train\n",
    "        labels = Y_train\n",
    "        def closure():\n",
    "            optimizer.zero_grad() # Setting our stored gradients equal to zero\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(torch.squeeze(outputs), labels) \n",
    "            loss.backward() # Computes the gradient of the given tensor w.r.t. the weights/bias\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure) # Updates weights and biases with the optimizer (SGD)\n",
    "        scheduler.step()\n",
    "        # print(scheduler.get_lr())\n",
    "        # loss = closure()[0]\n",
    "        # outputs = closure()[1]\n",
    "\n",
    "        iter+=1\n",
    "        if iter%1000==0:\n",
    "            with torch.no_grad():\n",
    "                # Calculating the loss and accuracy for the test dataset\n",
    "                correct_test = 0\n",
    "                total_test = 0\n",
    "                print(Y_train)\n",
    "                print(Y_test)\n",
    "                \n",
    "                outputs_test = torch.squeeze(model(X_test))\n",
    "                loss_test = criterion(outputs_test, Y_test)\n",
    "                print(f'model parameters: {list(model.parameters())}')\n",
    "\n",
    "                predicted_test = outputs_test.round().detach().numpy()\n",
    "                print(f'predictied test {predicted_test}')\n",
    "                \n",
    "                total_test += Y_test.size(0)\n",
    "                correct_test += np.sum(predicted_test == Y_test.detach().numpy())\n",
    "                accuracy_test = 100 * correct_test/total_test\n",
    "                losses_test.append(loss_test.item())\n",
    "                print(f\"Iteration: {iter}. \\nTest - Loss: {loss_test.item()}. Accuracy: {accuracy_test}\")\n",
    "                \n",
    "                print(outputs_test.size())\n",
    "                print(Y_test.size())\n",
    "\"\"\"\n",
    "                # Calculating the loss and accuracy for the train dataset\n",
    "                total = 0\n",
    "                correct = 0\n",
    "                total += Y_train.size(0)\n",
    "                correct += np.sum(torch.squeeze(outputs).round().detach().numpy() == Y_train.detach().numpy())\n",
    "                accuracy = 100 * correct/total\n",
    "                losses.append(loss.item())\n",
    "                Iterations.append(iter)\n",
    "\"\"\"\n",
    "                # print(f\"Iteration: {iter}. \\nTest - Loss: {loss_test.item()}. Accuracy: {accuracy_test}\")\n",
    "                # print(f\"Train -  Loss: {loss.item()}. Accuracy: {accuracy}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0285ad6",
   "metadata": {},
   "source": [
    "### (6) Test the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19816939",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc0b5418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
      "        0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
      "        0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 1.])\n",
      "tensor([1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "        0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 1., 1., 0.])\n",
      "model parameters: [Parameter containing:\n",
      "tensor([[ 0.3752,  0.4946, -0.0493, -0.0766,  0.0941,  0.1373]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0756], requires_grad=True)]\n",
      "predictied test [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Iteration: 1000. \n",
      "Test - Loss: 53.75. Accuracy: 46.25\n",
      "torch.Size([80])\n",
      "torch.Size([80])\n"
     ]
    }
   ],
   "source": [
    "training_model(criterion_SGD, optimizer_SGD, scheduler_SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4610cd03",
   "metadata": {},
   "source": [
    "Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b22058b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_model(criterion_Adam, optimizer_Adam, scheduler_Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e09838",
   "metadata": {},
   "source": [
    "LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74767f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_model(criterion_LBFGS, optimizer_LBFGS, scheduler_LBFGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5135f",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c0fcd",
   "metadata": {},
   "source": [
    "Learning rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c2dfd",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e20546e",
   "metadata": {},
   "source": [
    "Aufgaben:\n",
    "- Log_Reg_script in Pytorch implementieren (2 dimenionaler Datensatz, es wird einfacher. Alles, was im Script steht, muss gleich in Pytorch implementiert werden, die Grafiken auch).\n",
    "- Heart script verbessern, dafür muss ich die erlernte Gewichte von Matlab nehmen und hier vergleichen, das Resultat hier un in Matlab muss identisch sein.\n",
    "- Wenn ich mit allem fertig bin, muss SVM in Pytorch auch implementieren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1722c4",
   "metadata": {},
   "source": [
    "Der nächste Termin ist am 22.08 um 10:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c64df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
