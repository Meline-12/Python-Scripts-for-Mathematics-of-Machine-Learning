{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25899c84",
   "metadata": {},
   "source": [
    "## PyTorch installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082dcc7",
   "metadata": {},
   "source": [
    "pip install torch torchvision torchaudio\n",
    "\n",
    "for more information https://pytorch.org/get-started/locally/, https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer\n",
    "\n",
    "pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084eedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca9d1d",
   "metadata": {},
   "source": [
    "### (0) Preparing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data set\n",
    "T = np.loadtxt('heart.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(T[:, 13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the real features\n",
    "X_numpy = T[:, [0, 3, 4, 7, 9, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and transform the markers\n",
    "Y_numpy = T[:, 13] - 1\n",
    "print(Y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9fa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy array to tensor\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "print(X_numpy)\n",
    "print(X)\n",
    "print(X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32873bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy array to tensor\n",
    "Y = torch.from_numpy(Y_numpy.astype(np.float32))\n",
    "# Y = Y.view(Y.shape[0], 1)\n",
    "print(Y_numpy)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data pairs and features \n",
    "m, d = X.shape\n",
    "print(m, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8bfdb",
   "metadata": {},
   "source": [
    "### (1) Splitting our dataset into a train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc5bff",
   "metadata": {},
   "source": [
    "Random selection of the indices of the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428786b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share of training data\n",
    "p = 0.7\n",
    "data_ind = np.random.permutation(m)\n",
    "print((np.ceil(p*m)+1))\n",
    "ind_train = data_ind[:int((np.ceil(p*m)+1))]\n",
    "ind_test = [i for i in data_ind if i not in ind_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a13c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train = X[ind_train, :]\n",
    "Y_train = Y[ind_train]\n",
    "# print(X_train)\n",
    "# print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "X_test = X[ind_test, :]\n",
    "Y_test = Y[ind_test]\n",
    "# print(X_test)\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9975668a",
   "metadata": {},
   "source": [
    "### (2) Building the PyTorch Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "     def __init__(self, input_dim, output_dim):\n",
    "         super(LogisticRegression, self).__init__()\n",
    "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "     def forward(self, x):\n",
    "         outputs = torch.sigmoid(self.linear(x))\n",
    "         return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004994e",
   "metadata": {},
   "source": [
    "### (3) Initializing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6159e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning some hyper-parameters:\n",
    "epochs = 1000 # Indicates the number of passes through the entire training dataset the network has completed\n",
    "input_dim = d \n",
    "output_dim = 1 # Single output \n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f012bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78882187",
   "metadata": {},
   "source": [
    "### (4) Initializing the Loss Function and the Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9390e",
   "metadata": {},
   "source": [
    "##### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ceaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "criterion_SGD = torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD: Implements stochastic gradient descent (optionally with momentum)\n",
    "optimizer_SGD = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting learning rate\n",
    "# ExponentialLR: decays the learning rate of each parameter group by gamma every epoch.\n",
    "scheduler_SGD = torch.optim.lr_scheduler.ExponentialLR(optimizer_SGD, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c951a",
   "metadata": {},
   "source": [
    "##### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0196c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "criterion_Adam = torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam: Implements Adam algorithm\n",
    "optimizer_Adam = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ab33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_Adam = torch.optim.lr_scheduler.ExponentialLR(optimizer_Adam, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8ed3b0",
   "metadata": {},
   "source": [
    "##### LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "criterion_LBFGS = torch.nn.BCELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBFGS: Implements L-BFGS algorithm, heavily inspired by minFunc\n",
    "optimizer_LBFGS = torch.optim.LBFGS(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764eb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_LBFGS = torch.optim.lr_scheduler.ExponentialLR(optimizer_LBFGS, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e955d",
   "metadata": {},
   "source": [
    "### (5) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(criterion, optimizer, scheduler):\n",
    "    losses = []\n",
    "    losses_test = []\n",
    "    Iterations = []\n",
    "    iter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    # for epoch in tqdm(range(int(epochs)),desc='Training Epochs'):\n",
    "        x = X_train\n",
    "        labels = Y_train\n",
    "        def closure():\n",
    "            optimizer.zero_grad() # Setting our stored gradients equal to zero\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(torch.squeeze(outputs), labels) \n",
    "            loss.backward() # Computes the gradient of the given tensor w.r.t. the weights/bias\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure) # Updates weights and biases with the optimizer (SGD)\n",
    "        scheduler.step()\n",
    "        # print(scheduler.get_lr())\n",
    "        # loss = closure()[0]\n",
    "        # outputs = closure()[1]\n",
    "\n",
    "        iter+=1\n",
    "        if iter%1000==0:\n",
    "            with torch.no_grad():\n",
    "                # Calculating the loss and accuracy for the test dataset\n",
    "                correct_test = 0\n",
    "                total_test = 0\n",
    "                print(Y_train)\n",
    "                print(Y_test)\n",
    "                \n",
    "                outputs_test = torch.squeeze(model(X_test))\n",
    "                loss_test = criterion(outputs_test, Y_test)\n",
    "                print(f'model parameters: {list(model.parameters())}')\n",
    "\n",
    "                predicted_test = outputs_test.round().detach().numpy()\n",
    "                print(f'predictied test {predicted_test}')\n",
    "                \n",
    "                total_test += Y_test.size(0)\n",
    "                correct_test += np.sum(predicted_test == Y_test.detach().numpy())\n",
    "                accuracy_test = 100 * correct_test/total_test\n",
    "                losses_test.append(loss_test.item())\n",
    "                print(f\"Iteration: {iter}. \\nTest - Loss: {loss_test.item()}. Accuracy: {accuracy_test}\")\n",
    "                \n",
    "                print(outputs_test.size())\n",
    "                print(Y_test.size())\n",
    "\"\"\"\n",
    "                # Calculating the loss and accuracy for the train dataset\n",
    "                total = 0\n",
    "                correct = 0\n",
    "                total += Y_train.size(0)\n",
    "                correct += np.sum(torch.squeeze(outputs).round().detach().numpy() == Y_train.detach().numpy())\n",
    "                accuracy = 100 * correct/total\n",
    "                losses.append(loss.item())\n",
    "                Iterations.append(iter)\n",
    "\"\"\"\n",
    "                # print(f\"Iteration: {iter}. \\nTest - Loss: {loss_test.item()}. Accuracy: {accuracy_test}\")\n",
    "                # print(f\"Train -  Loss: {loss.item()}. Accuracy: {accuracy}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0285ad6",
   "metadata": {},
   "source": [
    "### (6) Test the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19816939",
   "metadata": {},
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model(criterion_SGD, optimizer_SGD, scheduler_SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4610cd03",
   "metadata": {},
   "source": [
    "Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22058b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_model(criterion_Adam, optimizer_Adam, scheduler_Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e09838",
   "metadata": {},
   "source": [
    "LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74767f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_model(criterion_LBFGS, optimizer_LBFGS, scheduler_LBFGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
