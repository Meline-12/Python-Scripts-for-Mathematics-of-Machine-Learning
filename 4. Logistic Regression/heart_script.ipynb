{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d27854b",
   "metadata": {},
   "source": [
    "# Mathematics of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb41502",
   "metadata": {},
   "source": [
    "## Programming tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa65dd",
   "metadata": {},
   "source": [
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55fcb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7d1a6",
   "metadata": {},
   "source": [
    "### a) Preparation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3d2c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70.  1.  4. ...  3.  3.  2.]\n",
      " [67.  0.  3. ...  0.  7.  1.]\n",
      " [57.  1.  2. ...  0.  7.  2.]\n",
      " ...\n",
      " [56.  0.  2. ...  0.  3.  1.]\n",
      " [57.  1.  4. ...  0.  6.  1.]\n",
      " [67.  1.  4. ...  3.  3.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# Loading the data set\n",
    "T = np.loadtxt('heart.dat')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26bb8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.00e+01 1.30e+02 3.22e+02 1.09e+02 2.40e+00 3.00e+00]\n",
      " [6.70e+01 1.15e+02 5.64e+02 1.60e+02 1.60e+00 0.00e+00]\n",
      " [5.70e+01 1.24e+02 2.61e+02 1.41e+02 3.00e-01 0.00e+00]\n",
      " ...\n",
      " [5.60e+01 1.40e+02 2.94e+02 1.53e+02 1.30e+00 0.00e+00]\n",
      " [5.70e+01 1.40e+02 1.92e+02 1.48e+02 4.00e-01 0.00e+00]\n",
      " [6.70e+01 1.60e+02 2.86e+02 1.08e+02 1.50e+00 3.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the real features\n",
    "X = T[:, [0, 3, 4, 7, 9, 11]]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a80d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.\n",
      " -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1.\n",
      "  1.  1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.\n",
      " -1. -1.  1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.  1.  1. -1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.\n",
      " -1.  1.  1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.\n",
      "  1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.\n",
      "  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1.\n",
      " -1.  1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1.\n",
      " -1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.\n",
      " -1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1.  1.\n",
      " -1.  1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1.\n",
      "  1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1. -1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Extract and transform the markers\n",
    "Y = 2 * T[:, 13] - 3\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f043d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    }
   ],
   "source": [
    "# Number of data pairs\n",
    "m = len(Y)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1bf3363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Number of features\n",
    "d = np.size(X, axis=1)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4445a5c",
   "metadata": {},
   "source": [
    "### b) Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec767c52",
   "metadata": {},
   "source": [
    "Random selection of the indices of the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b632d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190.0\n",
      "[168 125   7 218 134  94 252  54 208  85 264 197 152 104 165  34   0 214\n",
      " 222  75  16 200 238 262   1 216  31  95 192 106 203 115 145 253 127 123\n",
      "  80 113 230 229 102 256  51 150 130 236 247 250  40  72  49   6 217 186\n",
      "  42 227 148 265 204 187  52  25  61 267 221 107 189 169 114 117 185 138\n",
      " 195   4  87  74 136 132 158 224  83 249  35 146 142  66 160  39 251 261\n",
      " 135 257 240 231  56 258 194  22 118  58 112 164 170 198 202 196 263 176\n",
      "  44 174 259 268  21 235   3 156  97 248  10  37 183 188 151   9  23  73\n",
      " 153  43 175 149 191 223  64 133 155 228 108 119  45 266 172  50 139  38\n",
      " 254 244 184  91 109 162   8 205  60  68   5 233 143 213 178 126 242  24\n",
      " 220 163 207 232  84 234  11  67 210  36  89  53 122  28 144  27  46 209\n",
      "  33 180 147  86  62 212 190  63  48  88 129 166 255 201 128 141 101 199\n",
      " 193 237  98  92 260 121 173  65 206 171 100 239  12 211  29   2 219  93\n",
      " 241 140  30 110 215 243 105  26  57  69 269  17  59  77  55 116  99 182\n",
      "  82 179  90 245  78  81 161 131  70  47 120  32  76  13 159  14  71  79\n",
      "  18 177  41 225 124 226 246  96 167 154 137 157  19  15 103 111  20 181]\n",
      "270\n",
      "270\n",
      "[168 125   7 218 134  94 252  54 208  85 264 197 152 104 165  34   0 214\n",
      " 222  75  16 200 238 262   1 216  31  95 192 106 203 115 145 253 127 123\n",
      "  80 113 230 229 102 256  51 150 130 236 247 250  40  72  49   6 217 186\n",
      "  42 227 148 265 204 187  52  25  61 267 221 107 189 169 114 117 185 138\n",
      " 195   4  87  74 136 132 158 224  83 249  35 146 142  66 160  39 251 261\n",
      " 135 257 240 231  56 258 194  22 118  58 112 164 170 198 202 196 263 176\n",
      "  44 174 259 268  21 235   3 156  97 248  10  37 183 188 151   9  23  73\n",
      " 153  43 175 149 191 223  64 133 155 228 108 119  45 266 172  50 139  38\n",
      " 254 244 184  91 109 162   8 205  60  68   5 233 143 213 178 126 242  24\n",
      " 220 163 207 232  84 234  11  67 210  36  89  53 122  28 144  27  46 209\n",
      "  33 180 147  86  62 212 190  63  48  88]\n",
      "190\n",
      "[129, 166, 255, 201, 128, 141, 101, 199, 193, 237, 98, 92, 260, 121, 173, 65, 206, 171, 100, 239, 12, 211, 29, 2, 219, 93, 241, 140, 30, 110, 215, 243, 105, 26, 57, 69, 269, 17, 59, 77, 55, 116, 99, 182, 82, 179, 90, 245, 78, 81, 161, 131, 70, 47, 120, 32, 76, 13, 159, 14, 71, 79, 18, 177, 41, 225, 124, 226, 246, 96, 167, 154, 137, 157, 19, 15, 103, 111, 20, 181]\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# Share of training data\n",
    "p = 0.7\n",
    "data_ind = np.random.permutation(m)\n",
    "print((np.ceil(p*m)+1))\n",
    "ind_train = data_ind[:int((np.ceil(p*m)+1))]\n",
    "ind_test = [i for i in data_ind if i not in ind_train]\n",
    "\n",
    "\n",
    "print(data_ind)\n",
    "print(len(data_ind))\n",
    "print(len(set(data_ind)))\n",
    "print(ind_train)\n",
    "print(len(ind_train))\n",
    "print(ind_test)\n",
    "print(len(ind_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b47b965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.50e+01 1.38e+02 2.36e+02 1.52e+02 2.00e-01 0.00e+00]\n",
      " [5.40e+01 1.60e+02 2.01e+02 1.63e+02 0.00e+00 1.00e+00]\n",
      " [5.90e+01 1.10e+02 2.39e+02 1.42e+02 1.20e+00 1.00e+00]\n",
      " ...\n",
      " [6.00e+01 1.50e+02 2.40e+02 1.71e+02 9.00e-01 0.00e+00]\n",
      " [6.60e+01 1.60e+02 2.46e+02 1.20e+02 0.00e+00 3.00e+00]\n",
      " [4.10e+01 1.26e+02 3.06e+02 1.63e+02 0.00e+00 0.00e+00]]\n",
      "[-1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1.\n",
      " -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1.\n",
      "  1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.\n",
      " -1.  1.  1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.\n",
      " -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.\n",
      "  1. -1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.\n",
      " -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1.\n",
      "  1.  1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.\n",
      "  1. -1.  1. -1. -1. -1. -1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "X_train = X[ind_train, :]\n",
    "Y_train = Y[ind_train]\n",
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a2e0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.00e+01 1.17e+02 2.30e+02 1.60e+02 1.40e+00 2.00e+00]\n",
      " [5.00e+01 1.10e+02 2.54e+02 1.59e+02 0.00e+00 0.00e+00]\n",
      " [7.10e+01 1.60e+02 3.02e+02 1.62e+02 4.00e-01 2.00e+00]\n",
      " [5.80e+01 1.25e+02 3.00e+02 1.71e+02 0.00e+00 2.00e+00]\n",
      " [5.20e+01 1.34e+02 2.01e+02 1.58e+02 8.00e-01 1.00e+00]\n",
      " [5.90e+01 1.38e+02 2.71e+02 1.82e+02 0.00e+00 0.00e+00]\n",
      " [6.70e+01 1.20e+02 2.37e+02 7.10e+01 1.00e+00 0.00e+00]\n",
      " [7.70e+01 1.25e+02 3.04e+02 1.62e+02 0.00e+00 3.00e+00]\n",
      " [3.50e+01 1.26e+02 2.82e+02 1.56e+02 0.00e+00 0.00e+00]\n",
      " [4.30e+01 1.20e+02 1.77e+02 1.20e+02 2.50e+00 0.00e+00]\n",
      " [6.40e+01 1.40e+02 3.13e+02 1.33e+02 2.00e-01 0.00e+00]\n",
      " [5.40e+01 1.24e+02 2.66e+02 1.09e+02 2.20e+00 1.00e+00]\n",
      " [5.80e+01 1.20e+02 3.40e+02 1.72e+02 0.00e+00 0.00e+00]\n",
      " [5.40e+01 1.22e+02 2.86e+02 1.16e+02 3.20e+00 2.00e+00]\n",
      " [6.80e+01 1.20e+02 2.11e+02 1.15e+02 1.50e+00 0.00e+00]\n",
      " [5.70e+01 1.50e+02 2.76e+02 1.12e+02 6.00e-01 1.00e+00]\n",
      " [6.00e+01 1.02e+02 3.18e+02 1.60e+02 0.00e+00 1.00e+00]\n",
      " [6.90e+01 1.40e+02 2.54e+02 1.46e+02 2.00e+00 3.00e+00]\n",
      " [4.40e+01 1.08e+02 1.41e+02 1.75e+02 6.00e-01 0.00e+00]\n",
      " [5.20e+01 1.20e+02 3.25e+02 1.72e+02 2.00e-01 0.00e+00]\n",
      " [4.40e+01 1.40e+02 2.35e+02 1.80e+02 0.00e+00 0.00e+00]\n",
      " [5.10e+01 1.25e+02 2.45e+02 1.66e+02 2.40e+00 0.00e+00]\n",
      " [7.10e+01 1.10e+02 2.65e+02 1.30e+02 0.00e+00 1.00e+00]\n",
      " [5.70e+01 1.24e+02 2.61e+02 1.41e+02 3.00e-01 0.00e+00]\n",
      " [4.40e+01 1.20e+02 2.20e+02 1.70e+02 0.00e+00 0.00e+00]\n",
      " [5.40e+01 1.10e+02 2.06e+02 1.08e+02 0.00e+00 1.00e+00]\n",
      " [3.90e+01 1.40e+02 3.21e+02 1.82e+02 0.00e+00 0.00e+00]\n",
      " [6.40e+01 1.45e+02 2.12e+02 1.32e+02 2.00e+00 2.00e+00]\n",
      " [5.70e+01 1.28e+02 2.29e+02 1.50e+02 4.00e-01 1.00e+00]\n",
      " [5.50e+01 1.80e+02 3.27e+02 1.17e+02 3.40e+00 0.00e+00]\n",
      " [4.10e+01 1.30e+02 2.04e+02 1.72e+02 1.40e+00 0.00e+00]\n",
      " [6.20e+01 1.40e+02 2.68e+02 1.60e+02 3.60e+00 2.00e+00]\n",
      " [4.80e+01 1.24e+02 2.74e+02 1.66e+02 5.00e-01 0.00e+00]\n",
      " [4.60e+01 1.38e+02 2.43e+02 1.52e+02 0.00e+00 0.00e+00]\n",
      " [6.00e+01 1.20e+02 1.78e+02 9.60e+01 0.00e+00 0.00e+00]\n",
      " [4.70e+01 1.08e+02 2.43e+02 1.52e+02 0.00e+00 0.00e+00]\n",
      " [6.70e+01 1.60e+02 2.86e+02 1.08e+02 1.50e+00 3.00e+00]\n",
      " [5.30e+01 1.40e+02 2.03e+02 1.55e+02 3.10e+00 0.00e+00]\n",
      " [6.20e+01 1.20e+02 2.81e+02 1.03e+02 1.40e+00 1.00e+00]\n",
      " [3.90e+01 9.40e+01 1.99e+02 1.79e+02 0.00e+00 0.00e+00]\n",
      " [4.10e+01 1.05e+02 1.98e+02 1.68e+02 0.00e+00 1.00e+00]\n",
      " [4.60e+01 1.20e+02 2.49e+02 1.44e+02 8.00e-01 0.00e+00]\n",
      " [5.00e+01 1.20e+02 2.44e+02 1.62e+02 1.10e+00 0.00e+00]\n",
      " [4.10e+01 1.10e+02 1.72e+02 1.58e+02 0.00e+00 0.00e+00]\n",
      " [5.80e+01 1.50e+02 2.70e+02 1.11e+02 8.00e-01 0.00e+00]\n",
      " [5.00e+01 1.29e+02 1.96e+02 1.63e+02 0.00e+00 0.00e+00]\n",
      " [5.90e+01 1.40e+02 2.21e+02 1.64e+02 0.00e+00 0.00e+00]\n",
      " [6.00e+01 1.30e+02 2.53e+02 1.44e+02 1.40e+00 1.00e+00]\n",
      " [4.20e+01 1.20e+02 2.09e+02 1.73e+02 0.00e+00 0.00e+00]\n",
      " [3.50e+01 1.20e+02 1.98e+02 1.30e+02 1.60e+00 0.00e+00]\n",
      " [6.20e+01 1.50e+02 2.44e+02 1.54e+02 1.40e+00 0.00e+00]\n",
      " [6.60e+01 1.12e+02 2.12e+02 1.32e+02 1.00e-01 1.00e+00]\n",
      " [6.10e+01 1.20e+02 2.60e+02 1.40e+02 3.60e+00 1.00e+00]\n",
      " [4.40e+01 1.10e+02 1.97e+02 1.77e+02 0.00e+00 1.00e+00]\n",
      " [4.90e+01 1.20e+02 1.88e+02 1.39e+02 2.00e+00 3.00e+00]\n",
      " [3.70e+01 1.20e+02 2.15e+02 1.70e+02 0.00e+00 0.00e+00]\n",
      " [4.50e+01 1.04e+02 2.08e+02 1.48e+02 3.00e+00 0.00e+00]\n",
      " [6.10e+01 1.34e+02 2.34e+02 1.45e+02 2.60e+00 2.00e+00]\n",
      " [6.60e+01 1.78e+02 2.28e+02 1.65e+02 1.00e+00 2.00e+00]\n",
      " [5.70e+01 1.28e+02 3.03e+02 1.59e+02 0.00e+00 1.00e+00]\n",
      " [5.70e+01 1.20e+02 3.54e+02 1.63e+02 6.00e-01 0.00e+00]\n",
      " [5.60e+01 1.20e+02 2.36e+02 1.78e+02 8.00e-01 0.00e+00]\n",
      " [6.40e+01 1.10e+02 2.11e+02 1.44e+02 1.80e+00 0.00e+00]\n",
      " [4.60e+01 1.50e+02 2.31e+02 1.47e+02 3.60e+00 0.00e+00]\n",
      " [6.20e+01 1.24e+02 2.09e+02 1.63e+02 0.00e+00 0.00e+00]\n",
      " [4.10e+01 1.35e+02 2.03e+02 1.32e+02 0.00e+00 0.00e+00]\n",
      " [5.40e+01 1.25e+02 2.73e+02 1.52e+02 5.00e-01 1.00e+00]\n",
      " [6.20e+01 1.30e+02 2.63e+02 9.70e+01 1.20e+00 1.00e+00]\n",
      " [6.50e+01 1.10e+02 2.48e+02 1.58e+02 6.00e-01 2.00e+00]\n",
      " [6.60e+01 1.20e+02 3.02e+02 1.51e+02 4.00e-01 0.00e+00]\n",
      " [5.30e+01 1.30e+02 1.97e+02 1.52e+02 1.20e+00 0.00e+00]\n",
      " [5.10e+01 1.30e+02 2.56e+02 1.49e+02 5.00e-01 0.00e+00]\n",
      " [5.60e+01 1.25e+02 2.49e+02 1.44e+02 1.20e+00 1.00e+00]\n",
      " [4.50e+01 1.28e+02 3.08e+02 1.70e+02 0.00e+00 0.00e+00]\n",
      " [4.00e+01 1.40e+02 1.99e+02 1.78e+02 1.40e+00 0.00e+00]\n",
      " [7.10e+01 1.12e+02 1.49e+02 1.25e+02 1.60e+00 0.00e+00]\n",
      " [5.70e+01 1.65e+02 2.89e+02 1.24e+02 1.00e+00 3.00e+00]\n",
      " [4.10e+01 1.10e+02 2.35e+02 1.53e+02 0.00e+00 0.00e+00]\n",
      " [6.70e+01 1.20e+02 2.29e+02 1.29e+02 2.60e+00 2.00e+00]\n",
      " [5.60e+01 1.34e+02 4.09e+02 1.50e+02 1.90e+00 2.00e+00]]\n",
      "[ 1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1.\n",
      " -1. -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1.\n",
      "  1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.\n",
      "  1. -1. -1. -1.  1. -1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "X_test = X[ind_test, :]\n",
    "Y_test = Y[ind_test]\n",
    "print(X_test)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8bd04e",
   "metadata": {},
   "source": [
    "### c) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb73552",
   "metadata": {},
   "source": [
    "NOTE: We include the bias in the last position in the vector w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a98a48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical Risk Function\n",
    "# RS_log = @(w) mean( log(1 + exp(- Y_train .* (X_train * w(1:d) + w(end)))) , 1)\n",
    "def RS_log(w): return np.mean(np.log(1 + np.exp(-(np.multiply(Y_train, np.dot(X_train, w[0:d]) + w[-1])))), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67028ba",
   "metadata": {},
   "source": [
    "Numerical calculation of ERM parameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a6714b",
   "metadata": {},
   "source": [
    "... for this we allow enough iteration and choosing a random starting value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a69fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.473308\n",
      "         Iterations: 867\n",
      "         Function evaluations: 1312\n",
      "[-0.02460858  0.02001448  0.00547388 -0.02869171  0.67730437  1.00278759\n",
      " -0.11167897]\n",
      "0.4733083915639057\n",
      "867\n",
      "1312\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# np.random.normal(size=(d+1,1))\n",
    "w_LR, RS_min, iter, funcalls, warnflag = opt.fmin(RS_log, np.zeros((7, 1)), maxfun=100000, full_output=True)\n",
    "\n",
    "print(w_LR)\n",
    "print(RS_min)\n",
    "print(iter)\n",
    "print(funcalls)\n",
    "print(warnflag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d5827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2 percent of the training data is misclassified.\n"
     ]
    }
   ],
   "source": [
    "# Determine the misclassified training data via constraint violation:\n",
    "Err_Train = np.mean(np.multiply(Y_train, np.dot(X_train, w_LR[0:d]) + w_LR[-1]) < 0)\n",
    "print(\"{:.1f} percent of the training data is misclassified.\".format(Err_Train * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af683a9",
   "metadata": {},
   "source": [
    "ANSWER: If the sample were linearly separable, logistic regression would find the appropriate separating hypothesis. Because of the existing misclassifications, this is not that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a328f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.8 percent of the test data is misclassified.\n"
     ]
    }
   ],
   "source": [
    "# Determine the misclassified test data via constraint violation:\n",
    "Err_Test = np.mean(np.multiply(Y_test, np.dot(X_test, w_LR[0:d]) + w_LR[-1]) < 0)\n",
    "print(\"{:.1f} percent of the test data is misclassified.\".format(Err_Test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7943b",
   "metadata": {},
   "source": [
    "#### ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0d4d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So we estimate the expected risk of h_S to be 18.8 percent.\n"
     ]
    }
   ],
   "source": [
    "print(\"So we estimate the expected risk of h_S to be {:.1f} percent.\".format(Err_Test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d130ec0e",
   "metadata": {},
   "source": [
    "### d) Soft-margin SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa34a56",
   "metadata": {},
   "source": [
    "Choice of lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfa41d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both terms equally weighted\n",
    "lam = 1/m\n",
    "Y_train = Y_train[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2729196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def hinge(w, x, y): \n",
    "    # return np.amax(np.append(1 - np.multiply(y, (np.dot(x, w[0:d]) + w[-1])), np.zeros((len(y), 1)), axis = 1), axis = 1)\n",
    "    return np.amax(np.append(1 - np.multiply(Y_train, (np.dot(X_train, w[0:d]) + w[-1])), np.zeros((len(Y_train), 1)), axis = 1), axis = 1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26bb97e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.842107\n",
      "         Iterations: 61\n",
      "         Function evaluations: 1404\n",
      "         Gradient evaluations: 174\n",
      "[ 1.41389029e-09 -1.66170386e-08 -9.53661959e-09 -9.28719788e-09\n",
      " -1.09776492e-07 -2.36916540e-07 -9.99995396e-01]\n",
      "0.842107057414959\n"
     ]
    }
   ],
   "source": [
    "# Determine the solution\n",
    "def fun(w): return lam * np.linalg.norm(w[0:d])**2 + np.mean(hinge(w, X_train, Y_train))\n",
    "\n",
    "# w_SVM, RS_min, iter, funcalls, warnflag = opt.fmin(fun, np.random.randn(d+1, 1), maxfun=100000, full_output=True)\n",
    "result = opt.minimize(fun, np.random.randn(d+1, 1), options={'disp': True})\n",
    "\n",
    "w_SVM = result.x\n",
    "RS_min = result.fun\n",
    "\n",
    "print(w_SVM)\n",
    "print(RS_min)\n",
    "# print(iter)\n",
    "# print(funcalls)\n",
    "# print(warnflag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415b86fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.1 percent of the training data is misclassified.\n"
     ]
    }
   ],
   "source": [
    "# Determine the misclassified training data via constraint violation:\n",
    "Err_Train = np.mean(np.multiply(Y_train, np.dot(X_train, w_SVM[0:d]) + w_SVM[-1]) < 0)\n",
    "print(\"{:.1f} percent of the training data is misclassified.\".format(Err_Train * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "960f16d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0 percent of the test data is misclassified.\n"
     ]
    }
   ],
   "source": [
    "# Determine the misclassified test data via constraint violation:\n",
    "Err_Test = np.mean(np.multiply(Y_test, np.dot(X_test, w_SVM[0:d]) + w_SVM[-1]) < 0)\n",
    "print(\"{:.1f} percent of the test data is misclassified.\".format(Err_Test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93efb5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So we estimate the expected risk of h_S to be 50.0 percent.\n"
     ]
    }
   ],
   "source": [
    "print(\"So we estimate the expected risk of h_S to be {:.1f} percent.\".format(Err_Test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ab3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
